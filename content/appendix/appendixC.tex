%===================================== APPENDIX C =================================
\chapter{Callbacks API} \label{callbacks-api}

This appendix will explain how to use the custom callbacks in your Keras network script, and provide you with an API. For a presentation of the various visualization techniques explaining the underlying theory, see section \ref{visualization-theory} of the thesis.

\section*{Usage of Callbacks}

The API includes a wrapper class that allows for adding and initializing the custom callbacks in a simple and straightforward manner. The first thing you need to do is to import the wrapper class:

\begin{minted}
[
bgcolor=mygray
]
{python}
from custom_keras.callbacks import CustomCallbacks
\end{minted}

\noindent Then, you instantiate the wrapper class like this:

\begin{minted}
[
bgcolor=mygray
]
{python}
callbacks = CustomCallbacks(os.path.dirname(__file__))
\end{minted}

\noindent Note that to be able to use the \texttt{dirname} method you need to have the \texttt{os} package imported. The argument of the wrapper class should always be as shown above and is needed for the application to save the visualization results in the correct location. \\

\noindent To wrapper class provides you with methods for adding each of the available callbacks. For instance:

\begin{minted}
[
bgcolor=mygray
]
{python}
callbacks.register_deconvolutional_network(3, 16, interval=10)
\end{minted}

\noindent This shows the deconvolutional network visualization technique being added. For an explanation of the arguments, we refer you to the corresponding callbacks's description below. \\

\noindent When you are finished adding the callbacks that you wish to include, you can pass them to Keras' \texttt{.fit()} and \texttt{.fit\_generator()} methods as follows:

\begin{minted}
[
bgcolor=mygray
]
{python}
model.fit(x, y, callbacks=callbacks.get_list())
\end{minted}

\noindent You can also instantiate the callbacks separately, instead of using the wrapper class.

\subsection*{CustomCallbacks}

\begin{minted}
[
frame=single,
framesep=2mm,
baselinestretch=1.2,
fontsize=\footnotesize
]
{python}
custom_keras.callbacks.CustomCallbacks(file_folder, 
                                        custom_preprocess=None,
                                        custom_postprocess=None,
                                        base_interval=10)
\end{minted}

\noindent A wrapper class for callbacks. The arguments are arguments that two or more of the callbacks have in common. They will be passed on to the applicable callbacks when adding them.

\subsubsection*{Arguments}

\begin{itemize}
    \item \textbf{file\_folder:} Should always be \texttt{os.path.dirname(\_\_file\_\_)}.
    \item \textbf{custom\_preprocess:} A preprocess function that will be applied to the visualization input image before use.
    \item \textbf{custom\_postprocess:} A postprocess function that will be applied to the visualization output image before save.
    \item \textbf{base\_interval:} The base interval that the visualizations will be computed at, unless specified otherwise. Many of the callbacks have their own interval argument that can be set individually.
\end{itemize}

\subsubsection*{Methods}

The arguments of the wrapper methods correspond to the arguments of the associated callbacks, excluding \texttt{file\_folder}, \texttt{custom\_preprocess} and \texttt{custom\_postprocess}, which are set in the wrapper instantiation. Specifying the \texttt{interval} argument for a certain callback will override the \texttt{base\_interval} argument.

\begin{itemize}
    \item \textbf{get\_list:} Returns a list of all registered callbacks, to be passed to the Keras \texttt{.fit()} and \texttt{.fit\_generator()} methods.
    \item \textbf{register\_network\_saver:} Registers the \texttt{NetworkSaver} callback.
    \item \textbf{register\_training\_progress:} Registers the \texttt{TrainingProgress} calback.
    \item \textbf{register\_layer\_activations:} Registers the \texttt{LayerActivations} callback.
    \item \textbf{register\_saliency\_maps:} Registers the \texttt{SaliencyMaps} callback.
    \item \textbf{register\_deconvolutional\_network:} Registers the \texttt{DeconvolutionalNetwork} callback.
    \item \textbf{register\_deep\_visualization:} Registers the \texttt{DeepVisualization} callback.
\end{itemize}

\section*{Available Callbacks}

\subsection*{NetworkSaver}

\begin{minted}
[
frame=single,
framesep=2mm,
baselinestretch=1.2,
fontsize=\footnotesize
]
{python}
custom_keras.callbacks.NetworkSaver(file_folder)
\end{minted}

\noindent Saves the network after each epoch.

\subsubsection*{Arguments}

\begin{itemize}
    \item \textbf{file\_folder:} Should always be \texttt{os.path.dirname(\_\_file\_\_)}.
\end{itemize}

\subsection*{TrainingProgress}

\begin{minted}
[
frame=single,
framesep=2mm,
baselinestretch=1.2,
fontsize=\footnotesize
]
{python}
custom_keras.callbacks.TrainingProgress(file_folder)
\end{minted}

\noindent Saves training accuracy and loss after each batch. If validation is enabled, the callback will also save the validation accuracy and loss after each epoch. This callback assumes that accuracy is enabled as a metric in your Keras model.

\subsubsection*{Arguments}

\begin{itemize}
    \item \textbf{file\_folder:} Should always be \texttt{os.path.dirname(\_\_file\_\_)}.
\end{itemize}

\subsection*{LayerActivations}

\begin{minted}
[
frame=single,
framesep=2mm,
baselinestretch=1.2,
fontsize=\footnotesize
]
{python}
custom_keras.callbacks.LayerActivations(file_folder,
                                        exclude_layers=EXCLUDE_LAYERS, 
                                        custom_preprocess=None, 
                                        interval=10)
\end{minted}

\noindent Produces the layer activations for each layer of the network, except the excluded layers. 

\subsubsection*{Arguments}

\begin{itemize}
    \item \textbf{file\_folder:} Should always be \texttt{os.path.dirname(\_\_file\_\_)}.
    \item \textbf{exclude\_layers:} A tuple of Keras layers to exclude from visualization. The default value \texttt{EXCLUDE\_LAYERS} is a tuple containing \texttt{keras.layers.InputLayer}, \texttt{keras.layers.Dropout} and \texttt{keras.layers.Flatten}
    \item \textbf{custom\_preprocess:} A preprocess function that will be applied to the visualization input image before use.
    \item \textbf{interval:} The interval that the visualization will be computed at.
\end{itemize}

\subsection*{SaliencyMaps}

\begin{minted}
[
frame=single,
framesep=2mm,
baselinestretch=1.2,
fontsize=\footnotesize
]
{python}
custom_keras.callbacks.SaliencyMaps(file_folder, 
                                    custom_preprocess=None,
                                    custom_postprocess=None,
                                    interval=10)
\end{minted}

\noindent Produces a saliency map of the uploaded visualization image showing to what degree the pixels of the image influenced the result.

\subsubsection*{Arguments}

\begin{itemize}
    \item \textbf{file\_folder:} Should always be \texttt{os.path.dirname(\_\_file\_\_)}.
    \item \textbf{custom\_preprocess:} A preprocess function that will be applied to the visualization input image before use.
    \item \textbf{custom\_postprocess:} A postprocess function that will be applied to the visualization output image before save.
    \item \textbf{interval:} The interval that the visualization will be computed at.
\end{itemize}

\subsection*{DeconvolutionalNetwork}

\begin{minted}
[
frame=single,
framesep=2mm,
baselinestretch=1.2,
fontsize=\footnotesize
]
{python}
custom_keras.callbacks.DeconvolutionalNetwork(file_folder,
                                            feat_map_layer_no,
                                            feat_map_amount=None,
                                            feat_map_nos=None,
                                            custom_preprocess=None,
                                            custom_postprocess=None,
                                            custom_keras_model_info=None,
                                            interval=100)
\end{minted}

\noindent Produces visualizations of feature maps in the specified layer using a deconvolutional network and the uploaded visualization image. For simple convolutional models, the deconvolutional model can be automatically generated. For more complex convolutional models, the deconvolutional model created must be created by hand and passed to the callback.

\subsubsection*{Arguments}

\begin{itemize}
    \item \textbf{file\_folder:} Should always be \texttt{os.path.dirname(\_\_file\_\_)}.
    \item \textbf{feat\_map\_layer\_no:} The number of the layer whose feature maps should be visualized.
    \item \textbf{feat\_map\_amount:} The number of feature maps to visualize. The algorithm will choose the top \textit{N} maximally activated feature maps. If the argument is set to -1, all feature maps will be visualized. Note that either this or the \texttt{feat\_map\_nos} argument always needs to be specified.
    \item \textbf{feat\_map\_nos:} A list of numbers denoting which specific feature maps to visualize. Note that either this or the  \texttt{feat\_map\_amount} argument always needs to be specified.
    \item \textbf{custom\_preprocess:} A preprocess function that will be applied to the visualization input image before use.
    \item \textbf{custom\_postprocess:} A postprocess function that will be applied to the visualization output image before save.
    \item \textbf{custom\_keras\_model\_info:} Used to provide a deconvolutional model. Should be a tuple containing, in respective order, a deconvolutional Keras model based on your original model, a dictionary mapping from original model layer numbers to the corresponding deconvolutional model layer numbers, and an update method for the deconvolutional model which returns the updated deconvolutional model and layer map. If no update is needed, input an empty method.
    \item \textbf{interval:} The interval that the visualization will be computed at.
\end{itemize}

\subsection*{DeepVisualization}

\begin{minted}
[
frame=single,
framesep=2mm,
baselinestretch=1.2,
fontsize=\footnotesize
]
{python}
custom_keras.callbacks.DeepVisualization(file_folder,
                                        units_to_visualize,
                                        learning_rate,
                                        no_of_iterations,
                                        l2_decay=0,
                                        blur_interval=0,
                                        blur_std=0,
                                        value_percentile=0,
                                        norm_percentile=0,
                                        contribution_percentile=0,
                                        abs_contribution_percentile=0,
                                        custom_postprocess=None,
                                        interval=1000)
\end{minted}

\noindent Produces deep visualizations from the units selected. Involves a number of optional arguments for regularization values that can be set to employ various regularization techniques in order to produce interpretable visualizations. The regularization techniques available are $L_2$ decay, Gaussian blur and clipping based on specific attributes. Some useful combinations of the regularization values can be seen in \textbf{Table \ref{tab:reg_hyperparams}}.

\subsubsection*{Arguments}

\begin{itemize}
    \item \textbf{file\_folder:} Should always be \texttt{os.path.dirname(\_\_file\_\_)}.
    \item \textbf{units\_to\_visualize:} A list of tuples describing which units to be visualized. The tuples are on the form \texttt{(layer\_no, unit\_index)} where \texttt{unit\_index} is a number for layers with 1D output, like \texttt{keras.layers.Dense}, or a 3D tuple for layers with 3D output, like \texttt{keras.layers.Conv2D}.
    \item \textbf{learning\_rate:} The learning rate for updating the visualization image.
    \item \textbf{no\_of\_iterations:} The number of iterations to perform image optimization.
    \item \textbf{l2\_decay:} The strength of the $L_2$ decay regularization technique. Prevents a small number of extreme pixel values from dominating the output image. Requires values in range [0.0, 1.0].
    \item \textbf{blur\_interval:} The interval of employing the Gaussian blur regularization technique. Used to penalize high frequency information in the output image. Note that both this and the \texttt{blur\_std} argument needs to be specified to enable Guassian blurring. Requires values in range [0, inf).
    \item \textbf{blur\_std:} The standard deviation for the Gaussian blur kernel in the interval. Used to penalize high frequency information in the output image. Note that both this and the \texttt{blur\_interval} argument needs to be specified to enable Guassian blurring. Requires values in range [0.0, inf).
    \item \textbf{value\_percentile:} The value percentile limit. Used in clipping regularization to induce sparsity by setting pixels with a small absolute value to zero. Requires values in range [0, 100].
    \item \textbf{norm\_percentile:} The norm percentile limit. Used in clipping regularization to induce sparsity by setting pixels with small norm to zero. Requires values in range [0, 100].
    \item \textbf{contribution\_percentile:} [0, 100] The contribution percentile limit. Used in clipping regularization to induce sparsity by setting pixels with small contribution to zero. Requires values in range [0, 100].
    \item \textbf{abs\_contribution\_percentile:} The absolute contribution percentile limit. Used in clipping regularization to induce sparsity by setting pixels with small absolute contribution to zero. Requires values in range [0, 100].
    \item \textbf{custom\_postprocess:} A postprocess function that will be applied to the visualization output image before save.
    \item \textbf{interval:} The interval that the visualization will be computed at.
\end{itemize}

\cleardoublepage